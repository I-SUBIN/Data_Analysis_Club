{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant_seedling_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import glob\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dropout, Input, Dense, Activation,GlobalMaxPooling2D, BatchNormalization, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image, ImageOps\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#트레인 데이터 불러오기\n",
    "n = glob.glob('C:/Users/tnqls/Desktop/plant/train/*/*.png')\n",
    "ori_label = []\n",
    "ori_imgs = []\n",
    "for a in n:\n",
    "    if a[-3:] != 'png':\n",
    "        continue\n",
    "    ori_label.append(a.split('\\\\')[-2]) #파일 경로에서 파일 제목을 식물이름으로 저장하는 방법\n",
    "    open_img = Image.open(a)\n",
    "    ori_imgs.append(ImageOps.fit(open_img, (48,48), Image.ANTIALIAS).convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750\n",
      "4750\n",
      "<PIL.Image.Image image mode=RGB size=48x48 at 0x1CE84D58D48>\n",
      "Black-grass\n"
     ]
    }
   ],
   "source": [
    "#데이터 확인하기\n",
    "print(len(ori_imgs))\n",
    "print(len(ori_label))\n",
    "print(ori_imgs[0])\n",
    "print(ori_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 파일을 array형태로 변환\n",
    "imgs = np.array([np.array(im) for im in ori_imgs])\n",
    "imgs = imgs.reshape(imgs.shape[0], 48, 48, 3) / 255\n",
    "lb = LabelBinarizer().fit(ori_label)\n",
    "label = lb.transform(ori_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train데이터랑 valid데이터로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_img,valid_img,train_label,valid_label = train_test_split(imgs,label,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 만들기(기본)\n",
    "Zn_input = Input((48, 48, 3))\n",
    "\n",
    "Zn = Conv2D(16, (3, 3))(Zn_input)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(16, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = MaxPooling2D((2, 2), strides=(2, 2))(Zn)\n",
    "\n",
    "Zn = Conv2D(32, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(32, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "\n",
    "Zn = Conv2D(64, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(64, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = MaxPooling2D((2, 2), strides=(2, 2))(Zn)\n",
    "\n",
    "Zn = Conv2D(128, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(128, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = GlobalMaxPooling2D()(Zn)\n",
    "\n",
    "Zn = Dense(64, activation='relu')(Zn)\n",
    "Zn = Dropout(0.5)(Zn)\n",
    "Zn = Dense(32, activation='relu')(Zn)\n",
    "Zn = Dropout(0.5)(Zn)\n",
    "Zn = Dense(12, activation='softmax')(Zn)\n",
    "model_basic = Model(inputs=Zn_input, outputs=Zn)\n",
    "model_basic.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 46, 46, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 46, 46, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 44, 44, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 44, 44, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 18, 18, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 18, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 306,172\n",
      "Trainable params: 305,212\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#만들어진 모델 형태 확인하기\n",
    "model_basic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3800 samples, validate on 950 samples\n",
      "Epoch 1/150\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 2.6074 - acc: 0.1053 - val_loss: 2.4491 - val_acc: 0.1368\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.44906, saving model to model_basic.h5\n",
      "Epoch 2/150\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 2.3508 - acc: 0.1642 - val_loss: 2.4633 - val_acc: 0.1368\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.44906\n",
      "Epoch 3/150\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 2.1549 - acc: 0.2563 - val_loss: 2.4768 - val_acc: 0.1526\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.44906\n",
      "Epoch 4/150\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 1.9929 - acc: 0.3279 - val_loss: 2.5773 - val_acc: 0.2105\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.44906\n",
      "Epoch 5/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 1.8260 - acc: 0.3847 - val_loss: 3.1758 - val_acc: 0.1611\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.44906\n",
      "Epoch 6/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 1.6307 - acc: 0.4513 - val_loss: 3.6033 - val_acc: 0.1632\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.44906\n",
      "Epoch 7/150\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 1.5151 - acc: 0.4934 - val_loss: 2.9615 - val_acc: 0.2274\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.44906\n",
      "Epoch 8/150\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 1.4245 - acc: 0.5287 - val_loss: 2.7932 - val_acc: 0.2432\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.44906\n",
      "Epoch 9/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 1.3234 - acc: 0.5553 - val_loss: 1.8709 - val_acc: 0.4084\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.44906 to 1.87089, saving model to model_basic.h5\n",
      "Epoch 10/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 1.2307 - acc: 0.5908 - val_loss: 1.6737 - val_acc: 0.4789\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.87089 to 1.67367, saving model to model_basic.h5\n",
      "Epoch 11/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 1.1085 - acc: 0.6229 - val_loss: 1.0587 - val_acc: 0.6884\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.67367 to 1.05872, saving model to model_basic.h5\n",
      "Epoch 12/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 1.0685 - acc: 0.6455 - val_loss: 1.2237 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.05872\n",
      "Epoch 13/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 1.0184 - acc: 0.6584 - val_loss: 0.8484 - val_acc: 0.7274\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.05872 to 0.84844, saving model to model_basic.h5\n",
      "Epoch 14/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.9471 - acc: 0.6784 - val_loss: 0.6884 - val_acc: 0.7905\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.84844 to 0.68838, saving model to model_basic.h5\n",
      "Epoch 15/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.9111 - acc: 0.6955 - val_loss: 0.6048 - val_acc: 0.8074\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.68838 to 0.60479, saving model to model_basic.h5\n",
      "Epoch 16/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.8562 - acc: 0.7089 - val_loss: 0.6255 - val_acc: 0.7979\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.60479\n",
      "Epoch 17/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.8207 - acc: 0.7155 - val_loss: 0.6463 - val_acc: 0.7884\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.60479\n",
      "Epoch 18/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.7704 - acc: 0.7350 - val_loss: 0.6756 - val_acc: 0.7863\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.60479\n",
      "Epoch 19/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.7345 - acc: 0.7534 - val_loss: 0.5971 - val_acc: 0.8158\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.60479 to 0.59713, saving model to model_basic.h5\n",
      "Epoch 20/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.7228 - acc: 0.7529 - val_loss: 0.5583 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.59713 to 0.55830, saving model to model_basic.h5\n",
      "Epoch 21/150\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.6935 - acc: 0.7597 - val_loss: 0.5221 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.55830 to 0.52210, saving model to model_basic.h5\n",
      "Epoch 22/150\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.6677 - acc: 0.7655 - val_loss: 0.5229 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.52210\n",
      "Epoch 23/150\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.6685 - acc: 0.7647 - val_loss: 0.4906 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.52210 to 0.49055, saving model to model_basic.h5\n",
      "Epoch 24/150\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.6241 - acc: 0.7829 - val_loss: 0.4953 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.49055\n",
      "Epoch 25/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.6241 - acc: 0.7845 - val_loss: 0.4891 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.49055 to 0.48908, saving model to model_basic.h5\n",
      "Epoch 26/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.6194 - acc: 0.7761 - val_loss: 0.4811 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.48908 to 0.48108, saving model to model_basic.h5\n",
      "Epoch 27/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.6038 - acc: 0.7826 - val_loss: 0.4842 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.48108\n",
      "Epoch 28/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5882 - acc: 0.7932 - val_loss: 0.4756 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.48108 to 0.47555, saving model to model_basic.h5\n",
      "Epoch 29/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5944 - acc: 0.7911 - val_loss: 0.5094 - val_acc: 0.8389\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.47555\n",
      "Epoch 30/150\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.5813 - acc: 0.7937 - val_loss: 0.4736 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.47555 to 0.47355, saving model to model_basic.h5\n",
      "Epoch 31/150\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.5812 - acc: 0.7974 - val_loss: 0.4774 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.47355\n",
      "Epoch 32/150\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.5946 - acc: 0.7918 - val_loss: 0.4704 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.47355 to 0.47039, saving model to model_basic.h5\n",
      "Epoch 33/150\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.5720 - acc: 0.7911 - val_loss: 0.4635 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.47039 to 0.46353, saving model to model_basic.h5\n",
      "Epoch 34/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5412 - acc: 0.8092 - val_loss: 0.4800 - val_acc: 0.8495\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.46353\n",
      "Epoch 35/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5500 - acc: 0.8063 - val_loss: 0.4670 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.46353\n",
      "Epoch 36/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5457 - acc: 0.8032 - val_loss: 0.4655 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.46353\n",
      "Epoch 37/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5337 - acc: 0.8139 - val_loss: 0.4674 - val_acc: 0.8516\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.46353\n",
      "Epoch 38/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5409 - acc: 0.8061 - val_loss: 0.4643 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.46353\n",
      "Epoch 39/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5480 - acc: 0.8068 - val_loss: 0.4646 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.46353\n",
      "Epoch 40/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5340 - acc: 0.8158 - val_loss: 0.4602 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.46353 to 0.46021, saving model to model_basic.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5312 - acc: 0.8121 - val_loss: 0.4648 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.46021\n",
      "Epoch 42/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5226 - acc: 0.8216 - val_loss: 0.4572 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.46021 to 0.45724, saving model to model_basic.h5\n",
      "Epoch 43/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5353 - acc: 0.8095 - val_loss: 0.4645 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.45724\n",
      "Epoch 44/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5159 - acc: 0.8037 - val_loss: 0.4597 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.45724\n",
      "Epoch 45/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5274 - acc: 0.8058 - val_loss: 0.4636 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.45724\n",
      "Epoch 46/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5221 - acc: 0.8082 - val_loss: 0.4629 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.45724\n",
      "Epoch 47/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5086 - acc: 0.8239 - val_loss: 0.4606 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.45724\n",
      "Epoch 48/150\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.5315 - acc: 0.8084 - val_loss: 0.4600 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.45724\n",
      "Epoch 49/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5189 - acc: 0.8121 - val_loss: 0.4601 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.45724\n",
      "Epoch 50/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5092 - acc: 0.8168 - val_loss: 0.4611 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.45724\n",
      "Epoch 51/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5059 - acc: 0.8139 - val_loss: 0.4601 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.45724\n",
      "Epoch 52/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5061 - acc: 0.8242 - val_loss: 0.4559 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.45724 to 0.45591, saving model to model_basic.h5\n",
      "Epoch 53/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5120 - acc: 0.8192 - val_loss: 0.4562 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.45591\n",
      "Epoch 54/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.4970 - acc: 0.8261 - val_loss: 0.4573 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.45591\n",
      "Epoch 55/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5285 - acc: 0.8076 - val_loss: 0.4557 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.45591 to 0.45568, saving model to model_basic.h5\n",
      "Epoch 56/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5125 - acc: 0.8189 - val_loss: 0.4575 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.45568\n",
      "Epoch 57/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5029 - acc: 0.8213 - val_loss: 0.4577 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.45568\n",
      "Epoch 58/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5192 - acc: 0.8176 - val_loss: 0.4574 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.45568\n",
      "Epoch 59/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5143 - acc: 0.8197 - val_loss: 0.4574 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.45568\n",
      "Epoch 60/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5020 - acc: 0.8253 - val_loss: 0.4585 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.45568\n",
      "Epoch 61/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5067 - acc: 0.8174 - val_loss: 0.4574 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.45568\n",
      "Epoch 62/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.4966 - acc: 0.8192 - val_loss: 0.4575 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.45568\n",
      "Epoch 63/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5125 - acc: 0.8116 - val_loss: 0.4587 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.45568\n",
      "Epoch 64/150\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.5059 - acc: 0.8263 - val_loss: 0.4583 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.45568\n",
      "Epoch 65/150\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.5170 - acc: 0.8137 - val_loss: 0.4576 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.45568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ce8badbe88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 학습하기\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "modelsave = ModelCheckpoint(filepath='model_basic.h5', save_best_only=True, verbose=1)\n",
    "model_basic.fit(train_img, train_label, batch_size=64,epochs=150,validation_data=(valid_img, valid_label),callbacks=[annealer, earlystop, modelsave])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델만들기 Layer(128->256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 46, 46, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 46, 46, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 46, 46, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 44, 44, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 44, 44, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 44, 44, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 42, 42, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 42, 42, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 40, 40, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 40, 40, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 18, 18, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 18, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,201,660\n",
      "Trainable params: 1,199,676\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델만들기(layer 128->256)\n",
    "Zn_input = Input((48, 48, 3))\n",
    "Zn = Conv2D(16, (3, 3))(Zn_input)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(16, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "\n",
    "Zn = Conv2D(32, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(32, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = MaxPooling2D((2, 2), strides=(2, 2))(Zn)\n",
    "\n",
    "Zn = Conv2D(64, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(64, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "\n",
    "Zn = Conv2D(128, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(128, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = MaxPooling2D((2, 2), strides=(2, 2))(Zn)\n",
    "\n",
    "Zn = Conv2D(256, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(256, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = GlobalMaxPooling2D()(Zn)\n",
    "\n",
    "Zn = Dense(64, activation='relu')(Zn)\n",
    "Zn = Dropout(0.5)(Zn)\n",
    "Zn = Dense(32, activation='relu')(Zn)\n",
    "Zn = Dropout(0.5)(Zn)\n",
    "Zn = Dense(12, activation='softmax')(Zn)\n",
    "model_layer = Model(inputs=Zn_input, outputs=Zn)\n",
    "model_layer.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-4), metrics=['acc'])\n",
    "model_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3800 samples, validate on 950 samples\n",
      "Epoch 1/150\n",
      "3800/3800 [==============================] - 71s 19ms/step - loss: 2.5352 - acc: 0.1284 - val_loss: 2.4376 - val_acc: 0.1368\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.43762, saving model to model_layer.h5\n",
      "Epoch 2/150\n",
      "3800/3800 [==============================] - 69s 18ms/step - loss: 2.2475 - acc: 0.2187 - val_loss: 2.5062 - val_acc: 0.1368\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.43762\n",
      "Epoch 3/150\n",
      "3800/3800 [==============================] - 73s 19ms/step - loss: 2.0251 - acc: 0.3037 - val_loss: 3.9145 - val_acc: 0.1368\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.43762\n",
      "Epoch 4/150\n",
      "3800/3800 [==============================] - 78s 21ms/step - loss: 1.8310 - acc: 0.3800 - val_loss: 6.4095 - val_acc: 0.1368\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.43762\n",
      "Epoch 5/150\n",
      "3800/3800 [==============================] - 71s 19ms/step - loss: 1.6783 - acc: 0.4495 - val_loss: 8.5442 - val_acc: 0.1379\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.43762\n",
      "Epoch 6/150\n",
      "3800/3800 [==============================] - 68s 18ms/step - loss: 1.4983 - acc: 0.5005 - val_loss: 3.5252 - val_acc: 0.2168\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.43762\n",
      "Epoch 7/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 1.3752 - acc: 0.5445 - val_loss: 3.2402 - val_acc: 0.2811\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.43762\n",
      "Epoch 8/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 1.2148 - acc: 0.5979 - val_loss: 2.4458 - val_acc: 0.3758\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.43762\n",
      "Epoch 9/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 1.1139 - acc: 0.6324 - val_loss: 2.1218 - val_acc: 0.3516\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.43762 to 2.12176, saving model to model_layer.h5\n",
      "Epoch 10/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 1.0352 - acc: 0.6737 - val_loss: 2.3656 - val_acc: 0.4758\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.12176\n",
      "Epoch 11/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.9467 - acc: 0.6879 - val_loss: 1.2480 - val_acc: 0.6537\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.12176 to 1.24799, saving model to model_layer.h5\n",
      "Epoch 12/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 0.9048 - acc: 0.7008 - val_loss: 0.9276 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.24799 to 0.92756, saving model to model_layer.h5\n",
      "Epoch 13/150\n",
      "3800/3800 [==============================] - 68s 18ms/step - loss: 0.8125 - acc: 0.7363 - val_loss: 0.7576 - val_acc: 0.7832\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.92756 to 0.75758, saving model to model_layer.h5\n",
      "Epoch 14/150\n",
      "3800/3800 [==============================] - 72s 19ms/step - loss: 0.7858 - acc: 0.7358 - val_loss: 0.6622 - val_acc: 0.8053\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.75758 to 0.66215, saving model to model_layer.h5\n",
      "Epoch 15/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 0.7196 - acc: 0.7626 - val_loss: 0.5145 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.66215 to 0.51455, saving model to model_layer.h5\n",
      "Epoch 16/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 0.7205 - acc: 0.7600 - val_loss: 0.5196 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.51455\n",
      "Epoch 17/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.6409 - acc: 0.7811 - val_loss: 0.5348 - val_acc: 0.8358\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.51455\n",
      "Epoch 18/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.6301 - acc: 0.7939 - val_loss: 0.5300 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.51455\n",
      "Epoch 19/150\n",
      "3800/3800 [==============================] - 71s 19ms/step - loss: 0.6118 - acc: 0.7942 - val_loss: 0.4471 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.51455 to 0.44709, saving model to model_layer.h5\n",
      "Epoch 20/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.5810 - acc: 0.7958 - val_loss: 0.5625 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.44709\n",
      "Epoch 21/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.5254 - acc: 0.8163 - val_loss: 0.4994 - val_acc: 0.8516\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.44709\n",
      "Epoch 22/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 0.5208 - acc: 0.8147 - val_loss: 0.4263 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.44709 to 0.42630, saving model to model_layer.h5\n",
      "Epoch 23/150\n",
      "3800/3800 [==============================] - 69s 18ms/step - loss: 0.5227 - acc: 0.8166 - val_loss: 0.3987 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.42630 to 0.39870, saving model to model_layer.h5\n",
      "Epoch 24/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 0.4904 - acc: 0.8289 - val_loss: 0.4536 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.39870\n",
      "Epoch 25/150\n",
      "3800/3800 [==============================] - 70s 18ms/step - loss: 0.4888 - acc: 0.8261 - val_loss: 0.3934 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.39870 to 0.39339, saving model to model_layer.h5\n",
      "Epoch 26/150\n",
      "3800/3800 [==============================] - 69s 18ms/step - loss: 0.4801 - acc: 0.8276 - val_loss: 0.3951 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.39339\n",
      "Epoch 27/150\n",
      "3800/3800 [==============================] - 74s 19ms/step - loss: 0.4683 - acc: 0.8295 - val_loss: 0.3875 - val_acc: 0.8768\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.39339 to 0.38746, saving model to model_layer.h5\n",
      "Epoch 28/150\n",
      "3800/3800 [==============================] - 75s 20ms/step - loss: 0.4505 - acc: 0.8371 - val_loss: 0.3962 - val_acc: 0.8768\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38746\n",
      "Epoch 29/150\n",
      "3800/3800 [==============================] - 71s 19ms/step - loss: 0.4427 - acc: 0.8368 - val_loss: 0.4092 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38746\n",
      "Epoch 30/150\n",
      "3800/3800 [==============================] - 77s 20ms/step - loss: 0.4247 - acc: 0.8408 - val_loss: 0.4062 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38746\n",
      "Epoch 31/150\n",
      "3800/3800 [==============================] - 78s 20ms/step - loss: 0.4221 - acc: 0.8453 - val_loss: 0.3790 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.38746 to 0.37904, saving model to model_layer.h5\n",
      "Epoch 32/150\n",
      "3800/3800 [==============================] - 79s 21ms/step - loss: 0.4272 - acc: 0.8455 - val_loss: 0.3790 - val_acc: 0.8821\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.37904 to 0.37901, saving model to model_layer.h5\n",
      "Epoch 33/150\n",
      "3800/3800 [==============================] - 79s 21ms/step - loss: 0.4285 - acc: 0.8479 - val_loss: 0.3753 - val_acc: 0.8853\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.37901 to 0.37526, saving model to model_layer.h5\n",
      "Epoch 34/150\n",
      "3800/3800 [==============================] - 73s 19ms/step - loss: 0.4161 - acc: 0.8439 - val_loss: 0.3800 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.37526\n",
      "Epoch 35/150\n",
      "3800/3800 [==============================] - 76s 20ms/step - loss: 0.4170 - acc: 0.8495 - val_loss: 0.3829 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.37526\n",
      "Epoch 36/150\n",
      "3800/3800 [==============================] - 81s 21ms/step - loss: 0.4112 - acc: 0.8458 - val_loss: 0.3786 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.37526\n",
      "Epoch 37/150\n",
      "3800/3800 [==============================] - 83s 22ms/step - loss: 0.4196 - acc: 0.8492 - val_loss: 0.3871 - val_acc: 0.8853\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.37526\n",
      "Epoch 38/150\n",
      "3800/3800 [==============================] - 76s 20ms/step - loss: 0.3867 - acc: 0.8547 - val_loss: 0.3778 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.37526\n",
      "Epoch 39/150\n",
      "3800/3800 [==============================] - 76s 20ms/step - loss: 0.3874 - acc: 0.8603 - val_loss: 0.3754 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.37526\n",
      "Epoch 40/150\n",
      "3800/3800 [==============================] - 80s 21ms/step - loss: 0.3791 - acc: 0.8571 - val_loss: 0.3752 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.37526 to 0.37521, saving model to model_layer.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150\n",
      "3800/3800 [==============================] - 83s 22ms/step - loss: 0.3826 - acc: 0.8584 - val_loss: 0.3738 - val_acc: 0.8853\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.37521 to 0.37381, saving model to model_layer.h5\n",
      "Epoch 42/150\n",
      "3800/3800 [==============================] - 73s 19ms/step - loss: 0.4017 - acc: 0.8521 - val_loss: 0.3716 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.37381 to 0.37163, saving model to model_layer.h5\n",
      "Epoch 43/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 0.3885 - acc: 0.8547 - val_loss: 0.3747 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.37163\n",
      "Epoch 44/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.3751 - acc: 0.8632 - val_loss: 0.3736 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.37163\n",
      "Epoch 45/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 0.3848 - acc: 0.8547 - val_loss: 0.3663 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.37163 to 0.36627, saving model to model_layer.h5\n",
      "Epoch 46/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.3837 - acc: 0.8568 - val_loss: 0.3690 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.36627\n",
      "Epoch 47/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.3687 - acc: 0.8661 - val_loss: 0.3717 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.36627\n",
      "Epoch 48/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.3738 - acc: 0.8566 - val_loss: 0.3727 - val_acc: 0.8916\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.36627\n",
      "Epoch 49/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.3830 - acc: 0.8545 - val_loss: 0.3665 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.36627\n",
      "Epoch 50/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.3780 - acc: 0.8566 - val_loss: 0.3677 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.36627\n",
      "Epoch 51/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.3756 - acc: 0.8597 - val_loss: 0.3682 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.36627\n",
      "Epoch 52/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.3809 - acc: 0.8563 - val_loss: 0.3709 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.36627\n",
      "Epoch 53/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.3644 - acc: 0.8637 - val_loss: 0.3709 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.36627\n",
      "Epoch 54/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.3526 - acc: 0.8703 - val_loss: 0.3706 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.36627\n",
      "Epoch 55/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.3730 - acc: 0.8589 - val_loss: 0.3681 - val_acc: 0.8916\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.36627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ceb1af2c48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델(Layer 128->256) 학습하기\n",
    "#모델 학습하기\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "modelsave = ModelCheckpoint(filepath='model_layer.h5', save_best_only=True, verbose=1)\n",
    "model_layer.fit(train_img, train_label, batch_size=64,epochs=150,validation_data=(valid_img, valid_label),callbacks=[annealer, earlystop, modelsave])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델만들기(Batch size 64->32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 46, 46, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 46, 46, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 46, 46, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 44, 44, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 44, 44, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 44, 44, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 42, 42, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 42, 42, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 40, 40, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 40, 40, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 18, 18, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 18, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,201,660\n",
      "Trainable params: 1,199,676\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델만들기(Batchsize 64->32)\n",
    "model_batch = Model(inputs=Zn_input, outputs=Zn)\n",
    "model_batch.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-4), metrics=['acc'])\n",
    "model_batch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3800 samples, validate on 950 samples\n",
      "Epoch 1/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 1.2025 - acc: 0.6471 - val_loss: 2.8850 - val_acc: 0.4505\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.88500, saving model to model_batch.h5\n",
      "Epoch 2/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 1.0060 - acc: 0.6882 - val_loss: 2.1904 - val_acc: 0.5368\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.88500 to 2.19036, saving model to model_batch.h5\n",
      "Epoch 3/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.9217 - acc: 0.7282 - val_loss: 1.0785 - val_acc: 0.7021\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.19036 to 1.07853, saving model to model_batch.h5\n",
      "Epoch 4/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.8794 - acc: 0.7421 - val_loss: 1.1287 - val_acc: 0.6758\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.07853\n",
      "Epoch 5/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.7864 - acc: 0.7618 - val_loss: 1.7123 - val_acc: 0.6168\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.07853\n",
      "Epoch 6/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.7375 - acc: 0.7742 - val_loss: 1.2290 - val_acc: 0.6716\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.07853\n",
      "Epoch 7/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.6683 - acc: 0.7882 - val_loss: 0.5041 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.07853 to 0.50414, saving model to model_batch.h5\n",
      "Epoch 8/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.5948 - acc: 0.8147 - val_loss: 0.6088 - val_acc: 0.8168\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.50414\n",
      "Epoch 9/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.5722 - acc: 0.8232 - val_loss: 0.5414 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.50414\n",
      "Epoch 10/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 0.5304 - acc: 0.8292 - val_loss: 1.5964 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.50414\n",
      "Epoch 11/150\n",
      "3800/3800 [==============================] - 68s 18ms/step - loss: 0.5594 - acc: 0.8221 - val_loss: 0.5461 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.50414\n",
      "Epoch 12/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.4522 - acc: 0.8532 - val_loss: 0.4772 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.50414 to 0.47723, saving model to model_batch.h5\n",
      "Epoch 13/150\n",
      "3800/3800 [==============================] - 68s 18ms/step - loss: 0.4317 - acc: 0.8542 - val_loss: 0.4450 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.47723 to 0.44500, saving model to model_batch.h5\n",
      "Epoch 14/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.3911 - acc: 0.8579 - val_loss: 0.4725 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.44500\n",
      "Epoch 15/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.3864 - acc: 0.8679 - val_loss: 0.4146 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.44500 to 0.41457, saving model to model_batch.h5\n",
      "Epoch 16/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.3421 - acc: 0.8797 - val_loss: 0.4464 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.41457\n",
      "Epoch 17/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.3401 - acc: 0.8755 - val_loss: 0.4088 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.41457 to 0.40884, saving model to model_batch.h5\n",
      "Epoch 18/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.3548 - acc: 0.8718 - val_loss: 0.3854 - val_acc: 0.8853\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.40884 to 0.38541, saving model to model_batch.h5\n",
      "Epoch 19/150\n",
      "3800/3800 [==============================] - 65s 17ms/step - loss: 0.3323 - acc: 0.8753 - val_loss: 0.4001 - val_acc: 0.8811\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38541\n",
      "Epoch 20/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.3190 - acc: 0.8816 - val_loss: 0.4052 - val_acc: 0.8853\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38541\n",
      "Epoch 21/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.3248 - acc: 0.8813 - val_loss: 0.4154 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38541\n",
      "Epoch 22/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.2937 - acc: 0.8908 - val_loss: 0.4082 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38541\n",
      "Epoch 23/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.2927 - acc: 0.8858 - val_loss: 0.4096 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38541\n",
      "Epoch 24/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.2997 - acc: 0.8889 - val_loss: 0.4065 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38541\n",
      "Epoch 25/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.2867 - acc: 0.8889 - val_loss: 0.3991 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38541\n",
      "Epoch 26/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.2696 - acc: 0.8950 - val_loss: 0.3923 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38541\n",
      "Epoch 27/150\n",
      "3800/3800 [==============================] - 66s 17ms/step - loss: 0.2752 - acc: 0.8945 - val_loss: 0.4053 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38541\n",
      "Epoch 28/150\n",
      "3800/3800 [==============================] - 67s 18ms/step - loss: 0.2623 - acc: 0.8921 - val_loss: 0.3935 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ceb9c85cc8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델(Batchsize 64->32) 학습하기\n",
    "#모델 학습하기\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "modelsave = ModelCheckpoint(filepath='model_batch.h5', save_best_only=True, verbose=1)\n",
    "model_batch.fit(train_img, train_label, batch_size=32,epochs=150,validation_data=(valid_img, valid_label),callbacks=[annealer, earlystop, modelsave])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델만들기(이미지 사이즈 48->64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 62, 62, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 62, 62, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 62, 62, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 60, 60, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 60, 60, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 60, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 22, 22, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 22, 22, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_3 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 306,172\n",
      "Trainable params: 305,212\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#트레인 데이터 불러오기\n",
    "n = glob.glob('C:/Users/tnqls/Desktop/plant/train/*/*.png')\n",
    "ori_label = []\n",
    "ori_imgs = []\n",
    "for a in n:\n",
    "    if a[-3:] != 'png':\n",
    "        continue\n",
    "    ori_label.append(a.split('\\\\')[-2]) #파일 경로에서 파일 제목을 식물이름으로 저장하는 방법\n",
    "    open_img = Image.open(a)\n",
    "    ori_imgs.append(ImageOps.fit(open_img, (64,64), Image.ANTIALIAS).convert('RGB'))\n",
    "\n",
    "#이미지 파일을 array형태로 변환\n",
    "imgs = np.array([np.array(im) for im in ori_imgs])\n",
    "imgs = imgs.reshape(imgs.shape[0], 64, 64, 3) / 255\n",
    "lb = LabelBinarizer().fit(ori_label)\n",
    "label = lb.transform(ori_label)\n",
    "\n",
    "#train데이터랑 valid데이터로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_img,valid_img,train_label,valid_label = train_test_split(imgs,label,test_size=0.2,random_state=0)\n",
    "\n",
    "#모델만들기(이미지 사이즈 48->64)\n",
    "Zn_input = Input((64, 64, 3))\n",
    "Zn = Conv2D(16, (3, 3))(Zn_input)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(16, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = MaxPooling2D((2, 2), strides=(2, 2))(Zn)\n",
    "\n",
    "Zn = Conv2D(32, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(32, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "\n",
    "Zn = Conv2D(64, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(64, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = MaxPooling2D((2, 2), strides=(2, 2))(Zn)\n",
    "\n",
    "Zn = Conv2D(128, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = Conv2D(128, (3, 3))(Zn)\n",
    "Zn = BatchNormalization(axis = 3)(Zn)\n",
    "Zn = Activation('relu')(Zn)\n",
    "Zn = GlobalMaxPooling2D()(Zn)\n",
    "\n",
    "Zn = Dense(64, activation='relu')(Zn)\n",
    "Zn = Dropout(0.5)(Zn)\n",
    "Zn = Dense(32, activation='relu')(Zn)\n",
    "Zn = Dropout(0.5)(Zn)\n",
    "Zn = Dense(12, activation='softmax')(Zn)\n",
    "model_img = Model(inputs=Zn_input, outputs=Zn)\n",
    "model_img.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-4), metrics=['acc'])\n",
    "model_img.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3800 samples, validate on 950 samples\n",
      "Epoch 1/150\n",
      "3800/3800 [==============================] - 55s 15ms/step - loss: 2.6361 - acc: 0.1063 - val_loss: 2.4718 - val_acc: 0.0947\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.47184, saving model to model_img.h5\n",
      "Epoch 2/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 2.3358 - acc: 0.1742 - val_loss: 2.5185 - val_acc: 0.1095\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.47184\n",
      "Epoch 3/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 2.1415 - acc: 0.2716 - val_loss: 2.7843 - val_acc: 0.1337\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.47184\n",
      "Epoch 4/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 1.9672 - acc: 0.3297 - val_loss: 2.5409 - val_acc: 0.1337\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.47184\n",
      "Epoch 5/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 1.8123 - acc: 0.3911 - val_loss: 2.3226 - val_acc: 0.2600\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.47184 to 2.32261, saving model to model_img.h5\n",
      "Epoch 6/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 1.7089 - acc: 0.4363 - val_loss: 2.1944 - val_acc: 0.2895\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.32261 to 2.19441, saving model to model_img.h5\n",
      "Epoch 7/150\n",
      "3800/3800 [==============================] - 53s 14ms/step - loss: 1.5805 - acc: 0.4663 - val_loss: 2.1942 - val_acc: 0.3189\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.19441 to 2.19422, saving model to model_img.h5\n",
      "Epoch 8/150\n",
      "3800/3800 [==============================] - 53s 14ms/step - loss: 1.4956 - acc: 0.5005 - val_loss: 2.0154 - val_acc: 0.2968\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.19422 to 2.01535, saving model to model_img.h5\n",
      "Epoch 9/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 1.4071 - acc: 0.5237 - val_loss: 1.6683 - val_acc: 0.4474\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.01535 to 1.66831, saving model to model_img.h5\n",
      "Epoch 10/150\n",
      "3800/3800 [==============================] - 53s 14ms/step - loss: 1.3268 - acc: 0.5453 - val_loss: 1.8701 - val_acc: 0.3695\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.66831\n",
      "Epoch 11/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 1.2674 - acc: 0.5745 - val_loss: 1.3285 - val_acc: 0.5126\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.66831 to 1.32854, saving model to model_img.h5\n",
      "Epoch 12/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 1.1661 - acc: 0.6016 - val_loss: 1.2884 - val_acc: 0.5463\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.32854 to 1.28845, saving model to model_img.h5\n",
      "Epoch 13/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 1.1377 - acc: 0.6176 - val_loss: 0.9731 - val_acc: 0.6663\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.28845 to 0.97307, saving model to model_img.h5\n",
      "Epoch 14/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 1.0581 - acc: 0.6337 - val_loss: 0.7736 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.97307 to 0.77357, saving model to model_img.h5\n",
      "Epoch 15/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.9984 - acc: 0.6592 - val_loss: 0.7070 - val_acc: 0.7611\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.77357 to 0.70701, saving model to model_img.h5\n",
      "Epoch 16/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.9567 - acc: 0.6739 - val_loss: 0.8201 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.70701\n",
      "Epoch 17/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.9261 - acc: 0.6805 - val_loss: 0.7377 - val_acc: 0.7516\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.70701\n",
      "Epoch 18/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.8838 - acc: 0.6995 - val_loss: 0.6572 - val_acc: 0.7832\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.70701 to 0.65723, saving model to model_img.h5\n",
      "Epoch 19/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.8531 - acc: 0.6984 - val_loss: 0.6315 - val_acc: 0.7989\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.65723 to 0.63151, saving model to model_img.h5\n",
      "Epoch 20/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.8424 - acc: 0.7100 - val_loss: 0.5600 - val_acc: 0.8211\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.63151 to 0.56000, saving model to model_img.h5\n",
      "Epoch 21/150\n",
      "3800/3800 [==============================] - 53s 14ms/step - loss: 0.8212 - acc: 0.7195 - val_loss: 0.5672 - val_acc: 0.8179\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.56000\n",
      "Epoch 22/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.7870 - acc: 0.7284 - val_loss: 0.5679 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.56000\n",
      "Epoch 23/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.7543 - acc: 0.7326 - val_loss: 0.5736 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.56000\n",
      "Epoch 24/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.7253 - acc: 0.7350 - val_loss: 0.5511 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.56000 to 0.55114, saving model to model_img.h5\n",
      "Epoch 25/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.7253 - acc: 0.7434 - val_loss: 0.5317 - val_acc: 0.8358\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.55114 to 0.53168, saving model to model_img.h5\n",
      "Epoch 26/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.7350 - acc: 0.7397 - val_loss: 0.5197 - val_acc: 0.8358\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.53168 to 0.51974, saving model to model_img.h5\n",
      "Epoch 27/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.7142 - acc: 0.7471 - val_loss: 0.5209 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.51974\n",
      "Epoch 28/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.7013 - acc: 0.7524 - val_loss: 0.5060 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.51974 to 0.50599, saving model to model_img.h5\n",
      "Epoch 29/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6972 - acc: 0.7529 - val_loss: 0.5371 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.50599\n",
      "Epoch 30/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6597 - acc: 0.7642 - val_loss: 0.4910 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.50599 to 0.49098, saving model to model_img.h5\n",
      "Epoch 31/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6788 - acc: 0.7624 - val_loss: 0.4924 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.49098\n",
      "Epoch 32/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6587 - acc: 0.7642 - val_loss: 0.4995 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.49098\n",
      "Epoch 33/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6554 - acc: 0.7653 - val_loss: 0.4771 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.49098 to 0.47711, saving model to model_img.h5\n",
      "Epoch 34/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6401 - acc: 0.7718 - val_loss: 0.4706 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.47711 to 0.47056, saving model to model_img.h5\n",
      "Epoch 35/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6594 - acc: 0.7676 - val_loss: 0.4686 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.47056 to 0.46861, saving model to model_img.h5\n",
      "Epoch 36/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6585 - acc: 0.7703 - val_loss: 0.4644 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.46861 to 0.46438, saving model to model_img.h5\n",
      "Epoch 37/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6337 - acc: 0.7671 - val_loss: 0.4682 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.46438\n",
      "Epoch 38/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6341 - acc: 0.7776 - val_loss: 0.4654 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.46438\n",
      "Epoch 39/150\n",
      "3800/3800 [==============================] - 55s 15ms/step - loss: 0.6286 - acc: 0.7782 - val_loss: 0.4630 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.46438 to 0.46302, saving model to model_img.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6104 - acc: 0.7847 - val_loss: 0.4725 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.46302\n",
      "Epoch 41/150\n",
      "3800/3800 [==============================] - 56s 15ms/step - loss: 0.6014 - acc: 0.7858 - val_loss: 0.4638 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.46302\n",
      "Epoch 42/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6342 - acc: 0.7729 - val_loss: 0.4635 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.46302\n",
      "Epoch 43/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6281 - acc: 0.7779 - val_loss: 0.4579 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.46302 to 0.45795, saving model to model_img.h5\n",
      "Epoch 44/150\n",
      "3800/3800 [==============================] - 55s 15ms/step - loss: 0.6301 - acc: 0.7705 - val_loss: 0.4621 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.45795\n",
      "Epoch 45/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6104 - acc: 0.7755 - val_loss: 0.4643 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.45795\n",
      "Epoch 46/150\n",
      "3800/3800 [==============================] - 57s 15ms/step - loss: 0.6243 - acc: 0.7837 - val_loss: 0.4573 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.45795 to 0.45729, saving model to model_img.h5\n",
      "Epoch 47/150\n",
      "3800/3800 [==============================] - 59s 15ms/step - loss: 0.6161 - acc: 0.7697 - val_loss: 0.4594 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.45729\n",
      "Epoch 48/150\n",
      "3800/3800 [==============================] - 56s 15ms/step - loss: 0.6267 - acc: 0.7745 - val_loss: 0.4641 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.45729\n",
      "Epoch 49/150\n",
      "3800/3800 [==============================] - 58s 15ms/step - loss: 0.6007 - acc: 0.7821 - val_loss: 0.4631 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.45729\n",
      "Epoch 50/150\n",
      "3800/3800 [==============================] - 58s 15ms/step - loss: 0.6361 - acc: 0.7684 - val_loss: 0.4623 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.45729\n",
      "Epoch 51/150\n",
      "3800/3800 [==============================] - 59s 16ms/step - loss: 0.6070 - acc: 0.7805 - val_loss: 0.4606 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.45729\n",
      "Epoch 52/150\n",
      "3800/3800 [==============================] - 58s 15ms/step - loss: 0.6188 - acc: 0.7755 - val_loss: 0.4579 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.45729\n",
      "Epoch 53/150\n",
      "3800/3800 [==============================] - 57s 15ms/step - loss: 0.6044 - acc: 0.7887 - val_loss: 0.4585 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.45729\n",
      "Epoch 54/150\n",
      "3800/3800 [==============================] - 57s 15ms/step - loss: 0.6087 - acc: 0.7826 - val_loss: 0.4586 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.45729\n",
      "Epoch 55/150\n",
      "3800/3800 [==============================] - 57s 15ms/step - loss: 0.6024 - acc: 0.7811 - val_loss: 0.4575 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.45729\n",
      "Epoch 56/150\n",
      "3800/3800 [==============================] - 55s 14ms/step - loss: 0.6118 - acc: 0.7747 - val_loss: 0.4569 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.45729 to 0.45685, saving model to model_img.h5\n",
      "Epoch 57/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6255 - acc: 0.7718 - val_loss: 0.4581 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.45685\n",
      "Epoch 58/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6276 - acc: 0.7716 - val_loss: 0.4572 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.45685\n",
      "Epoch 59/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6156 - acc: 0.7792 - val_loss: 0.4572 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.45685\n",
      "Epoch 60/150\n",
      "3800/3800 [==============================] - 53s 14ms/step - loss: 0.6120 - acc: 0.7834 - val_loss: 0.4566 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.45685 to 0.45663, saving model to model_img.h5\n",
      "Epoch 61/150\n",
      "3800/3800 [==============================] - 53s 14ms/step - loss: 0.6143 - acc: 0.7758 - val_loss: 0.4573 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.45663\n",
      "Epoch 62/150\n",
      "3800/3800 [==============================] - 53s 14ms/step - loss: 0.6023 - acc: 0.7837 - val_loss: 0.4575 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.45663\n",
      "Epoch 63/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.5901 - acc: 0.7982 - val_loss: 0.4574 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.45663\n",
      "Epoch 64/150\n",
      "3800/3800 [==============================] - 55s 15ms/step - loss: 0.6113 - acc: 0.7782 - val_loss: 0.4571 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.45663\n",
      "Epoch 65/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6215 - acc: 0.7768 - val_loss: 0.4569 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.45663\n",
      "Epoch 66/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.5982 - acc: 0.7813 - val_loss: 0.4571 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.45663\n",
      "Epoch 67/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6161 - acc: 0.7792 - val_loss: 0.4579 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.45663\n",
      "Epoch 68/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6082 - acc: 0.7745 - val_loss: 0.4573 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.45663\n",
      "Epoch 69/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6099 - acc: 0.7805 - val_loss: 0.4571 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.45663\n",
      "Epoch 70/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.5949 - acc: 0.7818 - val_loss: 0.4566 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.45663 to 0.45659, saving model to model_img.h5\n",
      "Epoch 71/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6172 - acc: 0.7803 - val_loss: 0.4568 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.45659\n",
      "Epoch 72/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.5987 - acc: 0.7866 - val_loss: 0.4567 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.45659\n",
      "Epoch 73/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.5949 - acc: 0.7874 - val_loss: 0.4570 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.45659\n",
      "Epoch 74/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6038 - acc: 0.7842 - val_loss: 0.4569 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.45659\n",
      "Epoch 75/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.5927 - acc: 0.7758 - val_loss: 0.4568 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.45659\n",
      "Epoch 76/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.5929 - acc: 0.7847 - val_loss: 0.4570 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.45659\n",
      "Epoch 77/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.5906 - acc: 0.7876 - val_loss: 0.4571 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.45659\n",
      "Epoch 78/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6101 - acc: 0.7787 - val_loss: 0.4574 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.45659\n",
      "Epoch 79/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6029 - acc: 0.7803 - val_loss: 0.4574 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.45659\n",
      "Epoch 80/150\n",
      "3800/3800 [==============================] - 54s 14ms/step - loss: 0.6057 - acc: 0.7789 - val_loss: 0.4572 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.45659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ce92fd9ec8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델(이미지 크기) 학습하기\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "modelsave = ModelCheckpoint(filepath='model_img.h5', save_best_only=True, verbose=1)\n",
    "model_img.fit(train_img, train_label, batch_size=64,epochs=150,validation_data=(valid_img, valid_label),callbacks=[annealer, earlystop, modelsave])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test데이터 불러오기\n",
    "n = glob.glob('C:/Users/tnqls/Desktop/plant/test/*.png')\n",
    "test_img = []\n",
    "names = []\n",
    "for a in n:\n",
    "    if a[-3:] != 'png':\n",
    "        continue\n",
    "    names.append(a.split('\\\\')[-1])\n",
    "    new_img = Image.open(a)\n",
    "    test_img.append(ImageOps.fit(new_img, (48, 48), Image.ANTIALIAS).convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_batch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "timgs = np.array([np.array(im) for im in test_img])\n",
    "testX = timgs.reshape(timgs.shape[0], 48, 48, 3) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'file': names, 'species': test_y})\n",
    "df_sort = df.sort_values(by=['file'])\n",
    "df_sort.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
